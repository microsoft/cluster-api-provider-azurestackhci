---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AzureStackHCIMachineTemplate
metadata:
  name: "${CLUSTER_NAME}-md-0"
spec:
  template:
    spec:
      image:
        osType: "Linux"
      location: "westus"
      vmSize: ${AZURESTACKHCI_WORKER_MACHINE_TYPE}
      sshPublicKey: ${AZURESTACKHCI_SSH_PUBLIC_KEY}
---
kind: AzureStackHCIMachineTemplate
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
metadata:
  name: "${CLUSTER_NAME}-control-plane"
spec:
  template:
    spec:
      image:
        osType: "Linux"
      location: "westus"
      vmSize: ${AZURESTACKHCI_CONTROL_PLANE_MACHINE_TYPE}
      sshPublicKey: ${AZURESTACKHCI_SSH_PUBLIC_KEY}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: "${CLUSTER_NAME}-md-0"
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          name: '{{ ds.meta_data["local_hostname"] }}'
          kubeletExtraArgs:
            cloud-provider: external
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AzureStackHCIMachineTemplate
metadata:
  name: "${CLUSTER_NAME}-md-1"
spec:
  template:
    spec:  
      image:
        osType: "Windows"
      location: "westus"
      vmSize: ${AZURESTACKHCI_WINDOWS_WORKER_MACHINE_TYPE}
      sshPublicKey: ${AZURESTACKHCI_SSH_PUBLIC_KEY}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: "${CLUSTER_NAME}-md-1"
spec:
  template:
    spec:
      files:
        - path: C:\ECP-Cache\WaitForDocker.ps1
          permissions: "0744"
          content: |
            #ps1
            for($tries = 0; $tries -lt 2; $tries++) {
              for($i = 0; $i -lt 60; $i++) {
                if ((Get-Service docker).Status -eq "Running")
                {
                  echo "Docker service is running."
                  exit
                }
                echo "Waiting docker service..."
                start-sleep -s 2
              }
              & sc.exe start docker
              echo "Trying to start docker service..."
            }
      joinConfiguration:
        nodeRegistration:
          name: '{{ v1.local_hostname }}'
          kubeletExtraArgs:
            cloud-provider: external
      preKubeadmCommands:
        - powershell -c "mkdir -f C:\var\lib\kube-proxy\var\run\secrets\kubernetes.io\serviceaccount"
        - powershell -c "mkdir -f C:\var\lib\kubelet\pki"
        - icacls C:\etc\kubernetes /inheritance:r /grant Administrators:(OI)(CI)(IO)(F) /grant system:(OI)(CI)(IO)(F)
        - icacls C:\var\lib\kube-proxy\var\run\secrets\kubernetes.io\serviceaccount /inheritance:r /grant Administrators:(OI)(CI)(IO)(F) /grant system:(OI)(CI)(IO)(F)
        - icacls C:\var\lib\kubelet\pki /inheritance:r /grant Administrators:(OI)(CI)(IO)(F) /grant system:(OI)(CI)(IO)(F)
        - powershell C:\ECP-Cache\WaitForDocker.ps1
        - docker network create -d nat host
        - powershell -C "ipmo C:\ECP-Cache\hns.psm1;New-HNSNetwork -Type \"overlay\" -AddressPrefix \"192.168.255.0/30\" -Gateway \"192.168.255.1\" -Name \"External\" -AdapterName \"Ethernet 2\" -SubnetPolicies @(@{Type = \"VSID\"; VSID = 9999; }); start-sleep 10;"  
      postKubeadmCommands:
        - powershell C:\ECP-Cache\StartFlannel.ps1
        - copy C:\Users\Administrator\.ssh\authorized_keys C:\ProgramData\ssh\administrators_authorized_keys
        - icacls C:\ProgramData\ssh\administrators_authorized_keys /inheritance:r /grant "NT AUTHORITY\SYSTEM":R
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: Cluster
metadata:
  name: ${CLUSTER_NAME}
spec:
  clusterNetwork:
    pods:
      cidrBlocks: ["${AZURESTACKHCI_POD_CIDR}"]
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: AzureStackHCICluster
    name: ${CLUSTER_NAME}
  controlPlaneRef:
    kind: KubeadmControlPlane
    apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
    name: "${CLUSTER_NAME}-control-plane"
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AzureStackHCICluster
metadata:
  name: ${CLUSTER_NAME}
spec:
  resourceGroup: "${AZURESTACKHCI_CLUSTER_RESOURCE_GROUP}"
  location: "westus"
  networkSpec:
    vnet:
      name: "${AZURESTACKHCI_VNET_NAME}"
  azureStackHCILoadBalancer:
    image:
      osType: "Linux"
    sshPublicKey: ${AZURESTACKHCI_SSH_PUBLIC_KEY}
    vmSize: "${AZURESTACKHCI_LOAD_BALANCER_MACHINE_TYPE}"
  version: "${KUBERNETES_VERSION}"
---
kind: KubeadmControlPlane
apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
metadata:
  name: "${CLUSTER_NAME}-control-plane"
spec:
  replicas: ${CONTROL_PLANE_MACHINE_COUNT}
  infrastructureTemplate:
    kind: AzureStackHCIMachineTemplate
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    name: "${CLUSTER_NAME}-control-plane"
  kubeadmConfigSpec:
    preKubeadmCommands:
    - /etc/rc.d/init.d/docker-import-mcr-k8s.sh
    useExperimentalRetryJoin: true
    initConfiguration:
      nodeRegistration:
        name: '{{ ds.meta_data["local_hostname"] }}'
        kubeletExtraArgs:
          anonymous-auth: "false"
          cloud-provider: external
    joinConfiguration:
      nodeRegistration:
        name: '{{ ds.meta_data["local_hostname"] }}'
        kubeletExtraArgs: 
          cloud-provider: external
    clusterConfiguration:
      apiServer:
        timeoutForControlPlane: 20m
        extraArgs:
          cloud-provider: external
      controllerManager:
        extraArgs:
          terminated-pod-gc-threshold: "10"
          bind-address: "0.0.0.0"
          leader-elect-lease-duration: "60s"
          leader-elect-renew-deadline: "55s"
          cloud-provider: external
      scheduler:
        extraArgs:
          bind-address: "0.0.0.0"
          leader-elect-lease-duration: "60s"
          leader-elect-renew-deadline: "55s"
      imageRepository: "ecpacr.azurecr.io"
  version: "${KUBERNETES_VERSION}"
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  name: "${CLUSTER_NAME}-md-0"
spec:
  clusterName: "${CLUSTER_NAME}"
  replicas: ${WORKER_MACHINE_COUNT}
  selector:
    matchLabels: null
  template:
    spec:
      clusterName: "${CLUSTER_NAME}"
      version: "${KUBERNETES_VERSION}"
      bootstrap:
        configRef:
          name: "${CLUSTER_NAME}-md-0"
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
      infrastructureRef:
        name: "${CLUSTER_NAME}-md-0"
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: AzureStackHCIMachineTemplate
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  name: "${CLUSTER_NAME}-md-1"
spec:
  clusterName: "${CLUSTER_NAME}"
  replicas: ${AZURESTACKHCI_WINDOWS_WORKER_MACHINE_COUNT}
  selector:
    matchLabels:
  template:
    spec:
      clusterName: "${CLUSTER_NAME}"
      version: "${KUBERNETES_VERSION}"
      bootstrap:
        configRef:
          name: "${CLUSTER_NAME}-md-1"
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
      infrastructureRef:
        name: "${CLUSTER_NAME}-md-1"
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: AzureStackHCIMachineTemplate
